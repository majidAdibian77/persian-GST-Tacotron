
-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2022-01-04 22:23:30.870]  Checkpoint path: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/logs-tacotron/checkpoints/model.ckpt
[2022-01-04 22:23:30.870]  Loading training data from: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/training/train.txt
[2022-01-04 22:23:30.870]  Using model: tacotron
[2022-01-04 22:23:30.870]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 16
  checkpoint_interval: 4
  cleaners: english_cleaners
  decay_learning_rate: True
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 1000
  min_level_db: -100
  num_freq: 1025
  num_gst: 128
  num_heads: 4
  num_mels: 80
  outputs_per_step: 2
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  reference_depth: 128
  reference_filters: [32, 32, 64, 64, 128, 128]
  rnn_depth: 256
  sample_rate: 16000
  style_att_dim: 128
  style_att_type: mlp_attention
  style_embed_depth: 256
  summary_interval: 2
  use_cmudict: False
  use_gst: True
[2022-01-04 22:23:30.872]  Loaded metadata for 90 examples (0.13 hours)
[2022-01-04 22:23:37.779]  Initialized Tacotron model. Dimensions: 
[2022-01-04 22:23:37.779]    text embedding:          256
[2022-01-04 22:23:37.779]    style embedding:         256
[2022-01-04 22:23:37.779]    prenet out:              128
[2022-01-04 22:23:37.779]    encoder out:             512
[2022-01-04 22:23:37.779]    attention out:           256
[2022-01-04 22:23:37.780]    concat attn & out:       768
[2022-01-04 22:23:37.780]    decoder cell out:        256
[2022-01-04 22:23:37.780]    decoder out (2 frames):  160
[2022-01-04 22:23:37.780]    decoder out (1 frame):   80
[2022-01-04 22:23:37.780]    postnet out:             256
[2022-01-04 22:23:37.780]    linear out:              1025
[2022-01-04 22:23:51.887]  Starting new training run at commit: None
[2022-01-04 22:23:55.757]  Generated 32 batches of size 16 in 3.870 sec
[2022-01-04 22:24:21.346]  Step 1       [29.459 sec/step, loss=0.95188, avg_loss=0.95188]
[2022-01-04 22:24:23.063]  Step 2       [15.588 sec/step, loss=0.89710, avg_loss=0.92449]
[2022-01-04 22:24:23.063]  Writing summary at step: 2
[2022-01-04 22:24:46.451]  Step 3       [15.016 sec/step, loss=1.00291, avg_loss=0.95063]
[2022-01-04 22:24:53.703]  Step 4       [13.075 sec/step, loss=0.99889, avg_loss=0.96270]
[2022-01-04 22:24:53.703]  Writing summary at step: 4
[2022-01-04 22:25:03.820]  Saving checkpoint to: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/logs-tacotron/checkpoints/model.ckpt-4
[2022-01-04 22:25:05.671]  Saving audio and alignment...
[2022-01-04 22:25:10.345]  Input: TAkTEcOkOFTABAQEYEDOVVOMBUDi~____
[2022-01-04 22:25:22.747]  Step 5       [12.940 sec/step, loss=0.99491, avg_loss=0.96914]
[2022-01-04 22:25:27.433]  Step 6       [11.565 sec/step, loss=1.02177, avg_loss=0.97791]
[2022-01-04 22:25:27.433]  Writing summary at step: 6
[2022-01-04 22:26:04.603]  Step 7       [14.686 sec/step, loss=0.90065, avg_loss=0.96687]
[2022-01-04 22:26:06.963]  Step 8       [13.145 sec/step, loss=0.95660, avg_loss=0.96559]
[2022-01-04 22:26:06.963]  Writing summary at step: 8
[2022-01-04 22:26:13.010]  Saving checkpoint to: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/logs-tacotron/checkpoints/model.ckpt-8
[2022-01-04 22:26:14.471]  Saving audio and alignment...
[2022-01-04 22:26:17.660]  Input: iNOKTEYESEVVOMi~
[2022-01-04 22:26:27.570]  Step 9       [12.785 sec/step, loss=0.98855, avg_loss=0.96814]
[2022-01-04 22:26:30.812]  Step 10      [11.831 sec/step, loss=0.95889, avg_loss=0.96721]
[2022-01-04 22:26:30.813]  Writing summary at step: 10
[2022-01-04 22:26:43.584]  Step 11      [11.701 sec/step, loss=0.94477, avg_loss=0.96517]
[2022-01-04 22:26:50.683]  Step 12      [11.317 sec/step, loss=0.96209, avg_loss=0.96492]
[2022-01-04 22:26:50.683]  Writing summary at step: 12
[2022-01-04 22:26:53.569]  Saving checkpoint to: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/logs-tacotron/checkpoints/model.ckpt-12
[2022-01-04 22:26:55.080]  Saving audio and alignment...
[2022-01-04 22:27:01.219]  Input: icONBaYADsABRaiBasEKAMEiGOROSNEBEGOZARaNADi~_________
[2022-01-04 22:27:05.578]  Step 13      [10.782 sec/step, loss=0.97918, avg_loss=0.96601]
[2022-01-04 22:27:10.981]  Step 14      [10.398 sec/step, loss=0.97933, avg_loss=0.96696]
[2022-01-04 22:27:10.981]  Writing summary at step: 14
[2022-01-04 22:27:16.467]  Generated 32 batches of size 16 in 5.285 sec
[2022-01-04 22:27:27.215]  Step 15      [10.004 sec/step, loss=0.97621, avg_loss=0.96758]
[2022-01-04 22:27:29.740]  Step 16      [9.536 sec/step, loss=0.93548, avg_loss=0.96557]
[2022-01-04 22:27:29.740]  Writing summary at step: 16
[2022-01-04 22:27:34.422]  Saving checkpoint to: /content/drive/My Drive/Projects/TTS/multi speaker/GST_Tacotron/gst-tacotron/logs-tacotron/checkpoints/model.ckpt-16
[2022-01-04 22:27:35.944]  Saving audio and alignment...
[2022-01-04 22:27:42.838]  Input: iSARAsROZIREPATUKARDEOMaBAQIYEBADANRaBaKOTAsPUsaNDEBUDi~_______
[2022-01-04 22:27:46.536]  Step 17      [9.193 sec/step, loss=0.93026, avg_loss=0.96350]
